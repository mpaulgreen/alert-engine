#!/bin/bash

# OpenShift Infrastructure Setup Script for Alert Engine
# This script automates the setup of Kafka, Redis Cluster, and OpenShift Logging
# Based on alert_engine_infra_setup.md guide
# Enhanced for fully autonomous operation with robust error handling

set -e  # Exit on error
set -o pipefail  # Exit on pipe failure

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
STORAGE_CLASS="${STORAGE_CLASS:-gp3-csi}"
KAFKA_NAMESPACE="amq-streams-kafka"
REDIS_NAMESPACE="redis-cluster"
LOGGING_NAMESPACE="openshift-logging"
ALERT_ENGINE_NAMESPACE="alert-engine"

# Retry configuration
MAX_RETRIES=5
RETRY_DELAY=10

# Logging functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $(date '+%Y-%m-%d %H:%M:%S') $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $(date '+%Y-%m-%d %H:%M:%S') $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $(date '+%Y-%m-%d %H:%M:%S') $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $(date '+%Y-%m-%d %H:%M:%S') $1"
}

log_step() {
    echo -e "\n${BLUE}======================================${NC}"
    echo -e "${BLUE}$(date '+%Y-%m-%d %H:%M:%S') $1${NC}"
    echo -e "${BLUE}======================================${NC}"
}

# Enhanced retry function
retry_with_backoff() {
    local max_attempts=$1
    local delay=$2
    local command="${*:3}"
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        log_info "Attempting: $command (attempt $attempt/$max_attempts)"
        
        if eval "$command"; then
            log_success "Command succeeded on attempt $attempt"
            return 0
        else
            if [ $attempt -eq $max_attempts ]; then
                log_error "Command failed after $max_attempts attempts: $command"
                return 1
            fi
            
            log_warning "Attempt $attempt failed, retrying in ${delay}s..."
            sleep $delay
            attempt=$((attempt + 1))
            delay=$((delay * 2))  # Exponential backoff
        fi
    done
}

# Function to wait for resource condition with enhanced error handling
wait_for_condition() {
    local resource_type=$1
    local resource_name=$2
    local namespace=$3
    local condition=$4
    local timeout=${5:-300}
    
    log_info "Waiting for $resource_type/$resource_name to be $condition (timeout: ${timeout}s)..."
    
    local attempt=1
    local max_attempts=$((timeout / 10))
    
    while [ $attempt -le $max_attempts ]; do
        if oc get "$resource_type" "$resource_name" -n "$namespace" &>/dev/null; then
            if oc wait "$resource_type/$resource_name" --for="condition=$condition" --timeout=10s -n "$namespace" 2>/dev/null; then
                log_success "$resource_type/$resource_name is $condition"
                return 0
            fi
        fi
        
        log_info "Waiting for $resource_type/$resource_name ($attempt/$max_attempts)..."
        sleep 10
        attempt=$((attempt + 1))
    done
    
    log_error "Timeout waiting for $resource_type/$resource_name to be $condition"
    return 1
}

# Function to check if resource exists
resource_exists() {
    local resource_type=$1
    local resource_name=$2
    local namespace=$3
    
    if [ -n "$namespace" ]; then
        oc get "$resource_type" "$resource_name" -n "$namespace" &>/dev/null
    else
        oc get "$resource_type" "$resource_name" &>/dev/null
    fi
}

# Function to wait for pods to have IP addresses
wait_for_pod_ips() {
    local label_selector=$1
    local namespace=$2
    local expected_count=$3
    local timeout=${4:-300}
    
    log_info "Waiting for $expected_count pods with label '$label_selector' to have IP addresses..."
    
    local attempt=1
    local max_attempts=$((timeout / 5))
    
    while [ $attempt -le $max_attempts ]; do
        local pods_with_ips=$(oc get pods -l "$label_selector" -n "$namespace" -o jsonpath='{range .items[*]}{.status.podIP}{"\n"}{end}' 2>/dev/null | grep -v '^$' | wc -l)
        
        if [ "$pods_with_ips" -eq "$expected_count" ]; then
            log_success "All $expected_count pods have IP addresses"
            return 0
        fi
        
        log_info "Pods with IPs: $pods_with_ips/$expected_count (attempt $attempt/$max_attempts)"
        sleep 5
        attempt=$((attempt + 1))
    done
    
    log_error "Timeout waiting for pods to have IP addresses"
    return 1
}

# Enhanced auto-detect storage class function
auto_detect_storage_class() {
    log_info "Auto-detecting available storage class..."
    
    # Try the preferred storage class first
    if oc get storageclass "$STORAGE_CLASS" &>/dev/null; then
        log_success "Using preferred storage class: $STORAGE_CLASS"
        return 0
    fi
    
    log_warning "Preferred storage class '$STORAGE_CLASS' not found, auto-detecting..."
    
    # Look for common storage classes in order of preference
    local preferred_classes=("gp3-csi" "gp2" "standard" "fast" "slow")
    
    for class in "${preferred_classes[@]}"; do
        if oc get storageclass "$class" &>/dev/null; then
            STORAGE_CLASS="$class"
            log_success "Auto-detected storage class: $STORAGE_CLASS"
            return 0
        fi
    done
    
    # If no preferred class found, use the default one
    local default_class=$(oc get storageclass -o jsonpath='{.items[?(@.metadata.annotations.storageclass\.kubernetes\.io/is-default-class=="true")].metadata.name}' 2>/dev/null | head -n1)
    
    if [ -n "$default_class" ]; then
        STORAGE_CLASS="$default_class"
        log_success "Using default storage class: $STORAGE_CLASS"
        return 0
    fi
    
    # Last resort: use the first available storage class
    local first_class=$(oc get storageclass --no-headers -o custom-columns=NAME:.metadata.name 2>/dev/null | head -n1)
    
    if [ -n "$first_class" ]; then
        STORAGE_CLASS="$first_class"
        log_warning "Using first available storage class: $STORAGE_CLASS"
        return 0
    fi
    
    log_error "No storage class found in the cluster"
    return 1
}

# Prerequisites check
check_prerequisites() {
    log_step "CHECKING PREREQUISITES"
    
    # Check if oc CLI is available
    if ! command -v oc &> /dev/null; then
        log_error "oc CLI tool is not installed or not in PATH"
        exit 1
    fi
    
    # Check if we're logged into OpenShift
    if ! oc whoami &>/dev/null; then
        log_error "Not logged into OpenShift cluster. Please login first."
        exit 1
    fi
    
    # Check cluster-admin permissions
    if ! oc auth can-i '*' '*' --all-namespaces &>/dev/null; then
        log_error "Cluster-admin permissions required"
        exit 1
    fi
    
    # Auto-detect storage class
    auto_detect_storage_class
    
    # Ensure alert-engine namespace exists early
    log_info "Creating alert-engine namespace if it doesn't exist..."
    if ! resource_exists namespace "$ALERT_ENGINE_NAMESPACE"; then
        oc create namespace "$ALERT_ENGINE_NAMESPACE"
        log_success "Created namespace: $ALERT_ENGINE_NAMESPACE"
    else
        log_success "Namespace $ALERT_ENGINE_NAMESPACE already exists"
    fi
    
    log_success "Prerequisites check completed"
    log_info "Using storage class: $STORAGE_CLASS"
    log_info "Current user: $(oc whoami)"
    log_info "Current cluster: $(oc whoami --show-server)"
}

# Step 1: Kafka Setup using Red Hat AMQ Streams
setup_kafka() {
    log_step "STEP 1: KAFKA SETUP USING RED HAT AMQ STREAMS"
    
    # 1.1: Install AMQ Streams Operator
    log_info "1.1: Installing AMQ Streams Operator..."
    
    # Create namespace
    if ! resource_exists namespace "$KAFKA_NAMESPACE"; then
        oc create namespace "$KAFKA_NAMESPACE"
        log_success "Created namespace: $KAFKA_NAMESPACE"
    fi
    
    # Create OperatorGroup
    if ! resource_exists operatorgroup amq-streams-og "$KAFKA_NAMESPACE"; then
        cat <<EOF | oc apply -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: amq-streams-og
  namespace: $KAFKA_NAMESPACE
spec:
  targetNamespaces:
  - $KAFKA_NAMESPACE
EOF
        log_success "Created OperatorGroup"
    fi
    
    # Install operator subscription
    if ! resource_exists subscription amq-streams "$KAFKA_NAMESPACE"; then
        cat <<EOF | oc apply -f -
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: amq-streams
  namespace: $KAFKA_NAMESPACE
spec:
  channel: stable
  name: amq-streams
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
        log_success "Created AMQ Streams subscription"
    fi
    
    # 1.2: Validate AMQ Streams Operator Installation
    log_info "1.2: Validating AMQ Streams Operator installation..."
    
    # Wait for CSV to be successful with enhanced retry logic
    retry_with_backoff 60 5 "oc get csv -n '$KAFKA_NAMESPACE' --no-headers 2>/dev/null | grep -q 'amqstreams.*Succeeded'"
    
    # Verify operator pod is running
    retry_with_backoff 30 10 "oc get pods -n '$KAFKA_NAMESPACE' | grep -q 'amq-streams.*Running'"
    
    log_success "AMQ Streams operator installed successfully"
    
    # 1.3: Deploy Kafka Cluster
    log_info "1.3: Deploying Kafka cluster..."
    
    if ! resource_exists kafka alert-kafka-cluster "$KAFKA_NAMESPACE"; then
        cat <<EOF | oc apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: alert-kafka-cluster
  namespace: $KAFKA_NAMESPACE
spec:
  kafka:
    version: 3.9.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
        authentication:
          type: tls
      - name: external
        port: 9094
        type: route
        tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      inter.broker.protocol.version: "3.9"
      log.message.format.version: "3.9"
      auto.create.topics.enable: "false"
    storage:
      type: persistent-claim
      size: 100Gi
      class: $STORAGE_CLASS
    rack:
      topologyKey: topology.kubernetes.io/zone
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 4Gi
        cpu: 2000m
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 20Gi
      class: $STORAGE_CLASS
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 2Gi
        cpu: 1000m
  entityOperator:
    topicOperator:
      resources:
        requests:
          memory: 512Mi
          cpu: 200m
        limits:
          memory: 512Mi
          cpu: 500m
    userOperator:
      resources:
        requests:
          memory: 512Mi
          cpu: 200m
        limits:
          memory: 512Mi
          cpu: 500m
EOF
        log_success "Kafka cluster deployment initiated"
    fi
    
    # Wait for Kafka cluster to be ready with enhanced monitoring
    wait_for_condition kafka alert-kafka-cluster "$KAFKA_NAMESPACE" Ready 900
    
    # Verify all pods are running
    retry_with_backoff 30 10 "[ \$(oc get pods -n '$KAFKA_NAMESPACE' | grep -E '(kafka|zookeeper|entity-operator).*Running' | wc -l) -ge 7 ]"
    
    # 1.4: Create Kafka Topics
    log_info "1.4: Creating Kafka topics..."
    
    if ! resource_exists kafkatopic application-logs "$KAFKA_NAMESPACE"; then
        cat <<EOF | oc apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: application-logs
  namespace: $KAFKA_NAMESPACE
  labels:
    strimzi.io/cluster: alert-kafka-cluster
spec:
  partitions: 6
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824
    cleanup.policy: delete
EOF
        log_success "Created application-logs topic"
    fi
    
    # Wait for topic to be ready
    wait_for_condition kafkatopic application-logs "$KAFKA_NAMESPACE" Ready 300
    
    # 1.5 & 1.6: Verify and Test Kafka Installation
    log_info "1.5-1.6: Verifying and testing Kafka installation..."
    
    # Test Kafka producer-consumer flow with retry logic
    local test_message='{"timestamp":"'$(date -Iseconds)'","level":"INFO","message":"Test message from setup script","service":"kafka-test","namespace":"test"}'
    
    retry_with_backoff 3 5 "echo '$test_message' | oc exec -i -n '$KAFKA_NAMESPACE' alert-kafka-cluster-kafka-0 -- bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic application-logs"
    
    # Verify message can be consumed
    local message_received
    retry_with_backoff 3 5 "message_received=\$(oc exec -n '$KAFKA_NAMESPACE' alert-kafka-cluster-kafka-0 -- timeout 10 bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic application-logs --from-beginning --max-messages 1 2>/dev/null || true) && [[ \$message_received == *'kafka-test'* ]]"
    
    log_success "Kafka producer-consumer test passed"
    
    # 1.7: Create Kafka Network Policies
    log_info "1.7: Creating Kafka network policies..."
    
    cat <<EOF | oc apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: kafka-network-policy
  namespace: $KAFKA_NAMESPACE
spec:
  podSelector:
    matchLabels:
      strimzi.io/cluster: alert-kafka-cluster
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: $ALERT_ENGINE_NAMESPACE
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: $LOGGING_NAMESPACE
    ports:
    - protocol: TCP
      port: 9092
    - protocol: TCP
      port: 9093
  egress:
  - {}
EOF
    
    log_success "Kafka setup completed successfully"
}

# Step 2: Redis Cluster (HA) Setup with enhanced robustness
setup_redis() {
    log_step "STEP 2: REDIS CLUSTER (HA) SETUP"
    
    # 2.1: Create Redis Cluster Namespace
    log_info "2.1: Creating Redis cluster namespace..."
    
    if ! resource_exists namespace "$REDIS_NAMESPACE"; then
        oc create namespace "$REDIS_NAMESPACE"
        log_success "Created namespace: $REDIS_NAMESPACE"
    fi
    
    # 2.2: Deploy Redis Cluster
    log_info "2.2: Deploying Redis cluster..."
    
    # Create ConfigMap
    cat <<EOF | oc apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-cluster-config
  namespace: $REDIS_NAMESPACE
data:
  update-node.sh: |
    #!/bin/sh
    REDIS_NODES="/data/nodes.conf"
    if [ -f "\${REDIS_NODES}" ]; then
      sed -i -e "/myself/ s/[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}/\${POD_IP}/" \${REDIS_NODES}
    fi
    exec "\$@"
  redis.conf: |
    cluster-enabled yes
    cluster-require-full-coverage no
    cluster-node-timeout 15000
    cluster-config-file /data/nodes.conf
    cluster-migration-barrier 1
    appendonly yes
    protected-mode no
    bind 0.0.0.0
    port 6379
    tcp-keepalive 60
    maxmemory 256mb
    maxmemory-policy allkeys-lru
EOF
    
    # Create Service
    cat <<EOF | oc apply -f -
apiVersion: v1
kind: Service
metadata:
  name: redis-cluster
  namespace: $REDIS_NAMESPACE
  labels:
    app: redis-cluster
spec:
  ports:
  - port: 6379
    targetPort: 6379
    name: client
  - port: 16379
    targetPort: 16379
    name: gossip
  clusterIP: None
  selector:
    app: redis-cluster
EOF
    
    # Create StatefulSet
    cat <<EOF | oc apply -f -
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster
  namespace: $REDIS_NAMESPACE
spec:
  serviceName: redis-cluster
  replicas: 6
  selector:
    matchLabels:
      app: redis-cluster
  template:
    metadata:
      labels:
        app: redis-cluster
    spec:
      containers:
      - name: redis
        image: redis:7.0-alpine
        ports:
        - containerPort: 6379
          name: client
        - containerPort: 16379
          name: gossip
        command: ["/conf/update-node.sh", "redis-server", "/conf/redis.conf"]
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        volumeMounts:
        - name: conf
          mountPath: /conf
          readOnly: false
        - name: data
          mountPath: /data
          readOnly: false
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
      volumes:
      - name: conf
        configMap:
          name: redis-cluster-config
          defaultMode: 0755
          items:
          - key: redis.conf
            path: redis.conf
          - key: update-node.sh
            path: update-node.sh
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: $STORAGE_CLASS
      resources:
        requests:
          storage: 1Gi
EOF
    
    # Wait for all Redis pods to be ready with enhanced monitoring
    log_info "Waiting for Redis cluster pods to be ready..."
    
    # Wait for StatefulSet to have all replicas ready
    local attempt=1
    local max_attempts=60
    while [ $attempt -le $max_attempts ]; do
        local ready_replicas=$(oc get statefulset redis-cluster -n "$REDIS_NAMESPACE" -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
        if [ "$ready_replicas" -eq 6 ]; then
            log_success "StatefulSet redis-cluster has all 6 replicas ready"
            break
        fi
        log_info "StatefulSet ready replicas: $ready_replicas/6 (attempt $attempt/$max_attempts)"
        sleep 10
        attempt=$((attempt + 1))
    done
    
    if [ $attempt -gt $max_attempts ]; then
        log_error "Timeout waiting for StatefulSet redis-cluster to have 6 ready replicas"
        exit 1
    fi
    
    # Ensure all pods are running and ready
    retry_with_backoff 30 10 "[ \$(oc get pods -l app=redis-cluster -n '$REDIS_NAMESPACE' | grep '1/1.*Running' | wc -l) -eq 6 ]"
    
    # Wait for all pods to have IP addresses
    wait_for_pod_ips "app=redis-cluster" "$REDIS_NAMESPACE" 6 300
    
    # 2.3: Verify and Initialize Redis Cluster with robust retry logic
    log_info "2.3: Initializing Redis cluster..."
    
    # Wait additional time to ensure Redis servers are fully started
    log_info "Waiting for Redis servers to be fully initialized..."
    sleep 30
    
    # Verify Redis connectivity on all pods before cluster initialization
    for i in {0..5}; do
        retry_with_backoff 5 3 "oc exec redis-cluster-$i -n '$REDIS_NAMESPACE' -- redis-cli ping | grep -q PONG"
    done
    
    # Get Redis nodes IP addresses with validation
    log_info "Gathering Redis node IP addresses..."
    local redis_nodes=""
    local node_count=0
    
    for i in {0..5}; do
        local pod_ip=$(oc get pod redis-cluster-$i -n "$REDIS_NAMESPACE" -o jsonpath='{.status.podIP}' 2>/dev/null)
        if [ -n "$pod_ip" ] && [[ "$pod_ip" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            redis_nodes="$redis_nodes $pod_ip:6379"
            node_count=$((node_count + 1))
            log_info "Added node redis-cluster-$i: $pod_ip"
        else
            log_error "Failed to get valid IP for redis-cluster-$i: '$pod_ip'"
            exit 1
        fi
    done
    
    if [ $node_count -ne 6 ]; then
        log_error "Expected 6 Redis nodes, found $node_count"
        exit 1
    fi
    
    log_info "Redis cluster nodes:$redis_nodes"
    
    # Initialize the cluster with robust retry logic
    log_info "Initializing Redis cluster..."
    local cluster_init_success=false
    
    for attempt in {1..5}; do
        log_info "Cluster initialization attempt $attempt/5"
        
                 if oc exec redis-cluster-0 -n "$REDIS_NAMESPACE" -- redis-cli --cluster create $redis_nodes --cluster-replicas 1 --cluster-yes; then
            cluster_init_success=true
            break
        else
            log_warning "Cluster initialization attempt $attempt failed, retrying in 10s..."
            sleep 10
        fi
    done
    
    if [ "$cluster_init_success" != true ]; then
        log_error "Failed to initialize Redis cluster after 5 attempts"
        exit 1
    fi
    
    # Verify cluster status
    log_info "Verifying Redis cluster status..."
    retry_with_backoff 10 5 "oc exec redis-cluster-0 -n '$REDIS_NAMESPACE' -- redis-cli cluster info | grep -q 'cluster_state:ok'"
    
    local cluster_info=$(oc exec redis-cluster-0 -n "$REDIS_NAMESPACE" -- redis-cli cluster info)
    log_info "Cluster info: $cluster_info"
    
    # 2.4: Test Redis Cluster Connectivity
    log_info "2.4: Testing Redis cluster connectivity..."
    
    # Test with retry logic
    retry_with_backoff 5 3 "oc exec redis-cluster-0 -n '$REDIS_NAMESPACE' -- redis-cli -c set test-key 'Hello Redis Cluster'"
    
    local test_result
    retry_with_backoff 5 3 "test_result=\$(oc exec redis-cluster-0 -n '$REDIS_NAMESPACE' -- redis-cli -c get test-key) && [[ \$test_result == *'Hello Redis Cluster'* ]]"
    
    log_success "Redis cluster connectivity test passed"
    
    # Test on multiple nodes
    for i in 1 2; do
        retry_with_backoff 3 3 "oc exec redis-cluster-$i -n '$REDIS_NAMESPACE' -- redis-cli -c get test-key | grep -q 'Hello Redis Cluster'"
    done
    
    # Clean up test data
    oc exec redis-cluster-0 -n "$REDIS_NAMESPACE" -- redis-cli -c del test-key
    
    # 2.5: Create Redis Network Policies
    log_info "2.5: Creating Redis network policies..."
    
    cat <<EOF | oc apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: redis-cluster-network-policy
  namespace: $REDIS_NAMESPACE
spec:
  podSelector:
    matchLabels:
      app: redis-cluster
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: $ALERT_ENGINE_NAMESPACE
    ports:
    - protocol: TCP
      port: 6379
    - protocol: TCP
      port: 16379
  egress:
  - {}
EOF
    
    # 2.6: Create Redis access service and config
    log_info "2.6: Creating Redis connection details..."
    
    # Create alert-engine namespace if it doesn't exist
    if ! resource_exists namespace "$ALERT_ENGINE_NAMESPACE"; then
        oc create namespace "$ALERT_ENGINE_NAMESPACE"
    fi
    
    # Create service for Redis cluster access
    cat <<EOF | oc apply -f -
apiVersion: v1
kind: Service
metadata:
  name: redis-cluster-access
  namespace: $REDIS_NAMESPACE
spec:
  type: ClusterIP
  ports:
  - port: 6379
    targetPort: 6379
    protocol: TCP
    name: redis
  selector:
    app: redis-cluster
EOF
    
    # Create ConfigMap with Redis connection details
    cat <<EOF | oc apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: $ALERT_ENGINE_NAMESPACE
data:
  redis-mode: "cluster"
  redis-hosts: "redis-cluster-0.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379,redis-cluster-1.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379,redis-cluster-2.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379,redis-cluster-3.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379,redis-cluster-4.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379,redis-cluster-5.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379"
  redis-cluster-service: "redis-cluster-access.$REDIS_NAMESPACE.svc.cluster.local:6379"
  redis-namespace: "$REDIS_NAMESPACE"
EOF
    
    log_success "Redis cluster setup completed successfully"
}

# Step 3: OpenShift Logging and Log Forwarding Setup
setup_logging() {
    log_step "STEP 3: OPENSHIFT LOGGING AND LOG FORWARDING SETUP"
    
    # 3.1: Install OpenShift Logging Operator
    log_info "3.1: Installing OpenShift Logging Operator..."
    
    # Create namespace
    if ! resource_exists namespace "$LOGGING_NAMESPACE"; then
        oc create namespace "$LOGGING_NAMESPACE"
        log_success "Created namespace: $LOGGING_NAMESPACE"
    fi
    
    # Create OperatorGroup
    if ! resource_exists operatorgroup cluster-logging "$LOGGING_NAMESPACE"; then
        cat <<EOF | oc apply -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: cluster-logging
  namespace: $LOGGING_NAMESPACE
spec:
  targetNamespaces:
  - $LOGGING_NAMESPACE
EOF
        log_success "Created OperatorGroup for logging"
    fi
    
    # Install operator subscription
    if ! resource_exists subscription cluster-logging "$LOGGING_NAMESPACE"; then
        cat <<EOF | oc apply -f -
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: cluster-logging
  namespace: $LOGGING_NAMESPACE
spec:
  channel: stable-6.2
  name: cluster-logging
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
        log_success "Created cluster-logging subscription"
    fi
    
    # 3.2: Validate OpenShift Logging Operator Installation
    log_info "3.2: Validating OpenShift Logging Operator installation..."
    
    # Wait for CSV to be successful with enhanced retry logic
    retry_with_backoff 60 5 "oc get csv -n '$LOGGING_NAMESPACE' --no-headers 2>/dev/null | grep -q 'cluster-logging.*Succeeded'"
    
    # Verify operator pod is running
    retry_with_backoff 30 10 "oc get pods -n '$LOGGING_NAMESPACE' | grep -q 'cluster-logging-operator.*Running'"
    
    log_success "OpenShift Logging operator installed successfully"
    
    # 3.3: Create Service Account and RBAC
    log_info "3.3: Creating service account and RBAC..."
    
    cat <<EOF | oc apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: log-collector
  namespace: $LOGGING_NAMESPACE
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: log-collector-application-logs
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: collect-application-logs
subjects:
- kind: ServiceAccount
  name: log-collector
  namespace: $LOGGING_NAMESPACE
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: log-collector-write-logs
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: logging-collector-logs-writer
subjects:
- kind: ServiceAccount
  name: log-collector
  namespace: $LOGGING_NAMESPACE
EOF
    
    log_success "Service account and RBAC created"
    
    # 3.4: Deploy ClusterLogForwarder
    log_info "3.4: Deploying ClusterLogForwarder with namespace filtering..."
    
    cat <<EOF | oc apply -f -
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: kafka-forwarder
  namespace: $LOGGING_NAMESPACE
spec:
  outputs:
  - kafka:
      # CRITICAL: Use tcp:// prefix (RedHat fix)
      brokers:
      - tcp://alert-kafka-cluster-kafka-bootstrap.$KAFKA_NAMESPACE.svc.cluster.local:9092
      topic: application-logs
      tuning:
        compression: snappy
        # CRITICAL: Use deliveryMode instead of delivery (RedHat fix)
        deliveryMode: AtLeastOnce
    name: kafka-output
    type: kafka
  filters:
  - name: namespace-filter
    type: "drop"
    drop:
    - test:
      - field: .kubernetes.namespace_name
        notMatches: "phase0-logs"
  pipelines:
  - inputRefs:
    - application
    name: application-logs
    filterRefs:
    - namespace-filter
    outputRefs:
    - kafka-output
  serviceAccount:
    name: log-collector
EOF
    
    log_success "ClusterLogForwarder deployed"
    
    # Wait for ClusterLogForwarder to be processed
    sleep 30
    
    # 3.5: Deploy Test Application - DISABLED
    # Disable test application deployment for end-to-end validation
    if false; then
        log_info "3.5: Deploying test application for end-to-end validation..."
        
        # Create service account for alert-engine
        cat <<EOF | oc apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: alert-engine-sa
  namespace: $ALERT_ENGINE_NAMESPACE
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: alert-engine-role
rules:
- apiGroups: [""]
  resources: ["pods", "services", "endpoints", "persistentvolumeclaims", "events", "configmaps", "secrets"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments", "daemonsets", "replicasets", "statefulsets"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: alert-engine-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: alert-engine-role
subjects:
- kind: ServiceAccount
  name: alert-engine-sa
  namespace: $ALERT_ENGINE_NAMESPACE
EOF
        
        # Create continuous log generator deployment
        cat <<EOF | oc apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: continuous-log-generator
  namespace: $ALERT_ENGINE_NAMESPACE
  labels:
    app: continuous-log-generator
spec:
  replicas: 1
  selector:
    matchLabels:
      app: continuous-log-generator
  template:
    metadata:
      labels:
        app: continuous-log-generator
    spec:
      containers:
      - name: log-generator
        image: busybox:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Starting continuous random log generator..."
          counter=1
          while true; do
            level_num=\$((RANDOM % 5))
            service_num=\$((RANDOM % 5))
            message_num=\$((RANDOM % 10))
            
            case \$level_num in
              0) level="INFO" ;;
              1) level="WARN" ;;
              2) level="ERROR" ;;
              3) level="DEBUG" ;;
              4) level="TRACE" ;;
            esac
            
            case \$service_num in
              0) service="user-service" ;;
              1) service="payment-service" ;;
              2) service="order-service" ;;
              3) service="inventory-service" ;;
              4) service="notification-service" ;;
            esac
            
            case \$message_num in
              0) message="User authentication successful" ;;
              1) message="Payment processing initiated" ;;
              2) message="Order validation completed" ;;
              3) message="Inventory check performed" ;;
              4) message="Email notification sent" ;;
              5) message="Database connection established" ;;
              6) message="Cache operation completed" ;;
              7) message="API request processed" ;;
              8) message="File upload finished" ;;
              9) message="Session management handled" ;;
            esac
            
            timestamp=\$(date -Iseconds)
            user_id=\$((RANDOM % 1000 + 1))
            
            echo "[\$timestamp] \$level: \$message | service=\$service | user_id=\$user_id | sequence=\$counter"
            
            counter=\$((counter + 1))
            sleep 3
          done
        resources:
          requests:
            memory: "32Mi"
            cpu: "50m"
          limits:
            memory: "64Mi"
            cpu: "100m"
EOF
        
        # Wait for deployment to be ready
        wait_for_condition deployment continuous-log-generator "$ALERT_ENGINE_NAMESPACE" Available 300
        
        log_success "Test application deployed"
    fi
    
    # 3.6: Validate ClusterLogForwarder Configuration
    log_info "3.6: Validating ClusterLogForwarder deployment and configuration..."
    
    # Wait for ClusterLogForwarder to be processed and Vector pods to start
    log_info "Waiting 60 seconds for Vector to start processing the new configuration..."
    sleep 60
    
    # Validate ClusterLogForwarder configuration instead of looking for specific logs
    log_info "Checking ClusterLogForwarder configuration and status..."
    
    # Check if ClusterLogForwarder is valid
    local clf_status=$(oc get clusterlogforwarder kafka-forwarder -n "$LOGGING_NAMESPACE" -o jsonpath='{.status.conditions[?(@.type=="observability.openshift.io/Valid")].status}' 2>/dev/null || echo "Unknown")
    
    if [[ "$clf_status" == "True" ]]; then
        log_success "‚úÖ ClusterLogForwarder is valid and configured"
        
        # Check for namespace filtering configuration
        local has_filters=$(oc get clusterlogforwarder kafka-forwarder -n "$LOGGING_NAMESPACE" -o jsonpath='{.spec.filters}' 2>/dev/null)
        if [[ -n "$has_filters" ]]; then
            log_success "‚úÖ Namespace filtering is configured - only phase0-logs will be forwarded"
        else
            log_warning "‚ö†Ô∏è No namespace filtering detected - all application logs will be forwarded"
        fi
        
        # Check Vector pods are running
        local vector_pods=$(oc get pods -A -l app.kubernetes.io/component=collector --no-headers 2>/dev/null | grep -c Running || echo 0)
        if [[ $vector_pods -gt 0 ]]; then
            log_success "‚úÖ Vector log collector pods are running ($vector_pods pods)"
        else
            log_warning "‚ö†Ô∏è Vector log collector pods not found - log forwarding may not be active"
        fi
        
        log_success "‚úÖ ClusterLogForwarder configuration validation completed"
        log_info "Note: Only logs from phase0-logs namespace will be forwarded to Kafka"
        log_info "To test log forwarding, deploy applications in phase0-logs namespace"
    else
        log_warning "‚ö†Ô∏è ClusterLogForwarder status: $clf_status - configuration may need time to be processed"
        log_info "You can check status later with: oc get clusterlogforwarder kafka-forwarder -n $LOGGING_NAMESPACE -o yaml"
    fi
    
    log_success "OpenShift Logging and Log Forwarding setup completed with namespace filtering"
}

# Final validation with comprehensive checks
final_validation() {
    log_step "FINAL VALIDATION"
    
    log_info "Running comprehensive infrastructure validation..."
    
    local all_checks_passed=true
    
    # Kafka verification
    log_info "Checking Kafka cluster..."
    local kafka_ready=$(oc get kafka alert-kafka-cluster -n "$KAFKA_NAMESPACE" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "False")
    if [[ "$kafka_ready" == "True" ]]; then
        log_success "‚úÖ Kafka cluster ready"
    else
        log_error "‚ùå Kafka cluster not ready"
        all_checks_passed=false
    fi
    
    # Kafka pods verification
    local kafka_pods=$(oc get pods -n "$KAFKA_NAMESPACE" | grep -E '(kafka|zookeeper|entity-operator).*Running' | wc -l)
    if [[ "$kafka_pods" -ge 7 ]]; then
        log_success "‚úÖ Kafka pods running ($kafka_pods/7+)"
    else
        log_error "‚ùå Kafka pods not ready ($kafka_pods/7+)"
        all_checks_passed=false
    fi
    
    # Redis Cluster verification
    log_info "Checking Redis cluster..."
    local redis_pods=$(oc get pods -l app=redis-cluster -n "$REDIS_NAMESPACE" --no-headers 2>/dev/null | grep '1/1.*Running' | wc -l)
    if [[ "$redis_pods" -eq 6 ]]; then
        log_success "‚úÖ Redis cluster ready (6/6 pods)"
    else
        log_error "‚ùå Redis cluster not ready ($redis_pods/6 pods)"
        all_checks_passed=false
    fi
    
    # Redis cluster status verification
    local redis_cluster_state=$(oc exec redis-cluster-0 -n "$REDIS_NAMESPACE" -- redis-cli cluster info 2>/dev/null | grep cluster_state | cut -d: -f2 | tr -d '\r\n' || echo "fail")
    if [[ "$redis_cluster_state" == "ok" ]]; then
        log_success "‚úÖ Redis cluster state: ok"
    else
        log_error "‚ùå Redis cluster state: $redis_cluster_state"
        all_checks_passed=false
    fi
    
    # ClusterLogForwarder verification
    log_info "Checking ClusterLogForwarder..."
    local clf_exists=$(oc get clusterlogforwarder kafka-forwarder -n "$LOGGING_NAMESPACE" >/dev/null 2>&1 && echo "True" || echo "False")
    if [[ "$clf_exists" == "True" ]]; then
        log_success "‚úÖ ClusterLogForwarder deployed"
    else
        log_error "‚ùå ClusterLogForwarder not found"
        all_checks_passed=false
    fi
    
    # Test application verification - DISABLED since test app deployment was disabled
    # local test_app_ready=$(oc get deployment continuous-log-generator -n "$ALERT_ENGINE_NAMESPACE" -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
    # if [[ "$test_app_ready" -eq 1 ]]; then
    #     log_success "‚úÖ Test application running"
    # else
    #     log_error "‚ùå Test application not ready"
    #     all_checks_passed=false
    # fi
    log_info "‚ÑπÔ∏è Test application deployment disabled - skipping verification"
    
    # Network policies verification
    local kafka_netpol=$(oc get networkpolicy kafka-network-policy -n "$KAFKA_NAMESPACE" 2>/dev/null && echo "True" || echo "False")
    local redis_netpol=$(oc get networkpolicy redis-cluster-network-policy -n "$REDIS_NAMESPACE" 2>/dev/null && echo "True" || echo "False")
    
    if [[ "$kafka_netpol" == "True" && "$redis_netpol" == "True" ]]; then
        log_success "‚úÖ Network policies configured"
    else
        log_warning "‚ö†Ô∏è Some network policies missing (expected since test app is disabled)"
    fi
    
    # Summary
    if [ "$all_checks_passed" = true ]; then
        log_success "üéâ All infrastructure components are healthy and ready!"
    else
        log_error "‚ùå Some components failed validation. Check the logs above."
        exit 1
    fi
    
    log_step "CONNECTION DETAILS FOR ALERT ENGINE"
    echo "Kafka: alert-kafka-cluster-kafka-bootstrap.$KAFKA_NAMESPACE.svc.cluster.local:9092"
    echo "Redis: redis-cluster-access.$REDIS_NAMESPACE.svc.cluster.local:6379 (cluster mode)"
    echo "Topic: application-logs"
    echo "Namespace: $ALERT_ENGINE_NAMESPACE"
    echo "Storage Class: $STORAGE_CLASS"
    
    log_step "SAMPLE CONFIG.YAML FOR ALERT ENGINE"
    cat <<EOF
kafka:
  brokers: ["alert-kafka-cluster-kafka-bootstrap.$KAFKA_NAMESPACE.svc.cluster.local:9092"]
  topic: "application-logs"
  consumer_group: "alert-engine-group"

redis:
  mode: "cluster"
  addresses: [
    "redis-cluster-0.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379",
    "redis-cluster-1.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379",
    "redis-cluster-2.redis-cluster.$REDIS_NAMESPACE.svc.cluster.local:6379"
  ]

kubernetes:
  namespace: "$ALERT_ENGINE_NAMESPACE"
  service_account: "alert-engine-sa"
EOF
    
    log_success "üéâ OpenShift Infrastructure Setup Complete!"
}

# Main execution
main() {
    echo "=========================================="
    echo "OpenShift Infrastructure Setup for Alert Engine"
    echo "Enhanced Autonomous Version"
    echo "=========================================="
    echo ""
    echo "This script will automatically set up:"
    echo "- Red Hat AMQ Streams (Kafka)"
    echo "- Redis Cluster (HA)"
    echo "- OpenShift Logging with ClusterLogForwarder"
    echo "- Test applications and network policies"
    echo ""
    echo "Starting setup at $(date)..."
    echo ""
    
    check_prerequisites
    setup_kafka
    setup_redis
    setup_logging
    final_validation
    
    echo ""
    echo "Setup completed at $(date)"
    log_success "Infrastructure is ready for Alert Engine deployment!"
    log_info "Next steps:"
    echo "1. Update your Alert Engine config.yaml with the connection details above"
    echo "2. Deploy the Alert Engine using: oc apply -k deployments/alert-engine/"
    echo "3. Monitor the setup: oc get pods -n $ALERT_ENGINE_NAMESPACE"
    echo ""
}

# Error handling
trap 'log_error "Script failed at line $LINENO. Exit code: $?"' ERR

# Check if script is being sourced or executed
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi 